{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 Dirac Notation\n",
    "\n",
    "This chapter explains a bit of the framework for quantum computing using the maths from the last chapter. It's like learning the language of quantum computing, first the grammar was introduced in chapter 3, now we are defining the words.  \n",
    "\n",
    "## 4.1 Information inside a computer\n",
    "\n",
    "When using a computer everyday, it's important to be able to extract useful information from the computer. For instance, reading emails requires being able to access the information in your inbox. \n",
    "\n",
    "Unlike reading emails, quantum computing works at the lowest level of the system. It would be like directly accessing the bits in a classical computer. \n",
    "\n",
    "Instead of working with bits, quantum computing works with qubits. To do anything at all with qubits, it's important to describe what state they're in. The state of a qubit is described by something known as a ket. \n",
    "\n",
    "\n",
    "### 4.1.1 How do we describe the qubits?\n",
    "\n",
    "\n",
    "How do we represent a quantum state? It is easy to think this would require a very complicated mechanism. For us, it is as simple as a column vector! The state of a quantum system can be described with a column vector known as a ket. This is sometimes called the *statevector*. Usually, the state of a system is given by the ket $\\ket{\\psi}$. With $\n",
    "\n",
    "The coins still work as an example for the state. If the coin is heads up we can use the ket $\\ket{H}$, if it's tails up it is $\\ket{T}$. When the coin is spinning in the air, the superposition state (see section 1.3), this state can be represented by the state $\\ket{\\psi}$: \n",
    "\n",
    "$$\n",
    "\\ket{\\psi} = \\frac{1}{\\sqrt{2}}[\\ket{H} + \\ket{T}]\n",
    "$$\n",
    "\n",
    "Since the coin has a $\\frac{1}{2}$ probability of being in either heads or tails, one may have intuitively expected this state to have a $\\frac{1}{2}$ instead of $\\frac{1}{\\sqrt{2}}$. The reason for this is that in quantum mechanics, a state is described with an amplitude (the number outside the ket) proportional to the square root of the probability. \n",
    "\n",
    "It can be convenient to define the heads state using a ket as\n",
    "\n",
    "$$\n",
    "\\ket{H} = \n",
    "\n",
    "\\begin{bmatrix}\n",
    "1 \\\\ 0\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "Similarly, the tails side up can be represented by the ket\n",
    "\n",
    "$$\n",
    "\\ket{T} = \n",
    "\n",
    "\\begin{bmatrix}\n",
    "0 \\\\ 1\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "This allows $\\ket{\\psi} $ to be expanded as \n",
    "\n",
    "$$\n",
    "\\ket{\\psi} = \\frac{1}{\\sqrt{2}}\\left(\\begin{bmatrix}\n",
    "1 \\\\ 0\n",
    "\\end{bmatrix}+ \\begin{bmatrix}\n",
    "0 \\\\ 1\n",
    "\\end{bmatrix}\\right)\n",
    "$$\n",
    "\n",
    "By adding the corresponding elements of each vector, this can be simplified to\n",
    "\n",
    "$$ \\ket{\\psi} = \\frac{1}{\\sqrt{2}}\\begin{bmatrix} 1 \\\\ 1 \\end{bmatrix} $$\n",
    "\n",
    "Instead, if there were a biased coin which had a probability of heads given by $P$, the probability of tails would then be $1-P$. The state of the spinning coin could be represented as\n",
    "\n",
    "$$\n",
    "\\ket{\\psi} = \\sqrt{P}\\ket{H} + \\sqrt{1-P}\\ket{T}\n",
    "$$\n",
    "\n",
    "Or \n",
    "\n",
    "$$\n",
    "\\ket{\\psi} = \\begin{bmatrix}\n",
    "\\sqrt{P} \\\\ \\sqrt{1-P}\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "\n",
    "### 4.1.2 How to describe any quantum system \n",
    "\n",
    "More generally, the state of a quantum system $\\ket{\\psi}$ is referred to as a *wavefunction*\n",
    "\n",
    "The popular term to describe the state of a quantum system is the *wavefucntion*. Since we are using vectors to describe our quantum system it better to call it the *statevector*. \n",
    "\n",
    "\n",
    "In general, our quantum computer can take a lot more than 2 possible outcomes. Thankfully we can just add a row to our column vector for every possible outcome. So we can describe our state in terms of each possible outcome it can take.  We can write any quantum state by adding up all the possible states we can measure it in as\n",
    "\n",
    "$$\n",
    "\\ket{\\psi} = \\sum_{n = 0}^{N_1} c_n \\ket{n}\n",
    "$$\n",
    "\n",
    "\n",
    "Where the index $n$ indicates a possible state we can observe the quantum system in. There are $N$ such possible states. Each state has a probability of being measured given by $|c_n|^2$  with $c_n$ being the probability amplitude. \n",
    "\n",
    "Writing this as a statevector gives us \n",
    "\n",
    "$$\n",
    "\\ket{\\psi} = \\begin{bmatrix} c_0 \\\\ c_1 \\\\ c_2 \\\\ \\vdots \\\\ c_{N-2} \\\\ c_{N-1} \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "A little note here: to model the state of a quantum computer requires keeping track of $N$ complex numbers. That doesn't seem too bad but for $n$ qubits we have $N = 2^n$ complex numbers to keep track of. \n",
    "\n",
    "### 4.1.2 Row vectors\n",
    "\n",
    "Where the bra $\\bra{H}$ is the same as the ket $\\ket{H} = \\begin{bmatrix} 1 \\\\ 0 \\end{bmatrix}$ but a row vector where the imaginary part of the complex numbers are all multiplied by $-1$. Doing this to a vector is known as the *conjugate transpose*.  Since there are no imaginary numbers in $\\ket{H}$, the bra $\\bra{H}$ is just the transpose of the column vector as\n",
    "\n",
    "\n",
    "\n",
    "$$\n",
    "\\bra{H} = [\\ket{H}^*]^T = \\begin{bmatrix} 1 & 0 \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "\n",
    "## 4.2 Probability of measurement\n",
    "\n",
    "\n",
    "One of the most important features of quantum computing is measurement. Whenever we do a quantum computation, we change the state of the system. However the state itself is never directly observed. That's to say, we don't ever observe a superposition directly - there are not two coins where one is heads and the other is tails. \n",
    "\n",
    "Instead, we perform a measurement on the qubits to get some information out of them. It's like the lift analogy in Chapter 1, the lift is never observed between two floors, we only see it at the floors. We also don't observe part of the lift on one floor and part of the lift on another floor. Something has gone terribly wrong if the lift is split across multiple floors! \n",
    "\n",
    "The concept of measurement might seem a bit abstract, and it's admittedly one of the greatest unsolved problems in quantum mechanics. Thankfully we can continue to use the coins as an illustative example. For the coins, one may wish to know the probability of flipping the coin and getting heads or tails up. With Dirac notaion, the probability of an outcome (heads up) can be calculated using the inner product. Using the coin example, the probability of the coin ending up in the heads state $\\ket{H}$ can be calculated as\n",
    "\n",
    "$$ P(H) = |\\braket{H|\\psi}|^2  $$\n",
    "\n",
    "The state we want to measure $\\ket{H}$ is always on the left (in a bra) and the state we have, $\\psi$ is always on the right in a ket. Then we take the magnitude of the inner product and square it. \n",
    "\n",
    "Explicity computing this gives\n",
    "\n",
    "$$\n",
    "P(H) = |\\braket{H|\\psi}|^2 =   \\Bigg |\\frac{1}{\\sqrt{2}}\\begin{bmatrix} 1 & 0 \\end{bmatrix} \\begin{bmatrix} 1 \\\\ 1 \\end{bmatrix} \\Bigg |^2\n",
    "$$\n",
    "\n",
    "$$ = \\left| \\frac{1}{\\sqrt{2}} \\right|^2 = \\frac{1}{2} $$\n",
    "\n",
    "### Exercise 4.1\n",
    "\n",
    "Since all the probabilities of the coin landing on $\\ket{H}$ or $\\ket{T}$ must add to 1, for a biased or unbiased coin, it must be that $P(H) + P(T) = 1$. Let the probability of getting heads be $P$. This gives us a state of \n",
    "$$\n",
    "\\ket{\\psi} = \\begin{bmatrix} \\sqrt{P} \\\\ \\sqrt{1-P} \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "Using the defintion of the measurement probability, show that the probability of measuring heads and the probability of tails add up to 1. \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "For any quantum state, the probability of measuring it to be in the state that it is must be 1. For example, if the coin were heads up, and nothing happened to the coin, the probability of measuring heads would be 1. The probability of getting a tails would be 0. This can be verified by working out the probability of measuring tails. The probability of measuring tails $P(T)$ is still given by the same equation \n",
    "\n",
    "$$ P(T) = |\\braket{T|\\psi}|^2 $$ \n",
    "\n",
    "where the coin is in the state $\\ket{\\psi}$ = $\\ket{H}$. \n",
    "\n",
    "$$  \n",
    "\\left| \\begin{bmatrix} 0 & 1 \\end{bmatrix} \\begin{bmatrix} 1 \\\\ 0 \\end{bmatrix} \\right|^2 \n",
    "$$\n",
    "\n",
    "$$\n",
    "= \\left| (0 \\times 1) + (1 \\times 0) \\right|^2 = 0 \n",
    "$$\n",
    "\n",
    "\n",
    "On the other hand, the proability of measuring a heads is 1. Whilst this result may seem obvious, it is worth emphasising that for any quantum state, the probability of measuring it in that state should be 1 (neglecting measurement error). This leaves us the important result\n",
    "\n",
    "$$ |\\braket{\\psi|\\psi}|^2 = 1 $$\n",
    "\n",
    "Another way of thinking about this is that for any quantum system, the probabilities of finding it in each of its states must add up to 1. This means $ |\\braket{\\psi|\\psi}|^2 = 1 $ must hold for any quantum state. \n",
    "\n",
    "## 4.3 Operators: A trip to the casino \n",
    "\n",
    "An operator is a mathematical object that acts on a ket and returns a new ket. Operators are matrices that allow us to process quantum states. \n",
    "\n",
    "In general terms, an operator denoted by a capital letter, such as  $O$, acts on a quantum state $\\ket{\\psi}$ to return a new state $\\ket{\\psi'}$ as \n",
    "\n",
    "$$\n",
    "O\\ket{\\psi} = \\ket{\\psi'}\n",
    "$$\n",
    "\n",
    "In gambling, the outcome of some event results in the gambler winning or losing money. Imagine a very simple game where everytime you roll a heads you win $1, everytime you roll a tails, you lose $1. \n",
    "\n",
    "We can define an operator, let's call it $Z$ that encodes the winnings and loses for each coin toss. \n",
    "\n",
    "If we roll a heads $\\ket{H}$ we should get +1, so we can encode that as \n",
    "\n",
    "$$\n",
    "Z\\ket{H} = +1 \\ket{H}\n",
    "$$\n",
    "\n",
    "Where the coefficient +1 is the winnings and the final state $\\ket{H}$ is what we end up with. \n",
    "\n",
    "Similarly for tails we lose a dollar so \n",
    "\n",
    "$$\n",
    "Z\\ket{T} = -1 \\ket{T}\n",
    "$$\n",
    "\n",
    "Using the vector representation of $\\ket{H}, \\ket{T}$ we can write the matrix $Z$\n",
    "\n",
    "$$ Z = \\begin{bmatrix} 1 & 0 \\\\ 0 & -1 \\end{bmatrix} $$\n",
    "\n",
    "It turns out $Z$ is an important quantum logic gate!\n",
    "\n",
    "It is easy to see how this could be scaled to any number of possible outcomes as a diagonal matrix. \n",
    "\n",
    "## 4.4 What do we expect to get?\n",
    "\n",
    "In life there are many processes where we want to predict something. For instance, a farmer would want to know how good their next harvest would be, or a stockbroker would want to know whether or not a stock is going to go up or down in price. In those cases, the farmer is not interested in the probability of getting an exact crop yeild, but wants to know what yeild they should expect. Quantum mechanics allows us to caluate these expectation values.\n",
    "\n",
    "### 4.4.1 Classical probability \n",
    "\n",
    "What would we expect to get from our coin example? \n",
    "\n",
    "We know that half the time we will get $1, and half the time we will lose $1. \n",
    "\n",
    "So our expected winnings, $\\braket{E}$ would be\n",
    "\n",
    "\n",
    "$$\n",
    "\\braket{E} = \\frac{1}{2} \\times 1 + \\frac{1}{2} \\times -1 \n",
    "=0\n",
    "$$\n",
    "\n",
    "More generally we can write the expectation value in terms of the value of each outcome and the probability \n",
    "\n",
    "$$ \\braket{E} = \\sum_{i = 0}^{N-1} X_i \\times P(i) $$\n",
    "\n",
    "Where $X_i$ is the outcome for event $i$ with probability $P(i)$ . \n",
    "\n",
    "\n",
    "### Exercise 4.2 Expectation value\n",
    "\n",
    "For this question, we're graduating from a coin to a dice. Let's call $N$ the number on a dice. Work out the expectation value by working out the number on each dice multiplied by the probability of rolling that number. \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### 4.4.2 A quantum description of probability \n",
    "\n",
    "So far this description of probability is entirely classical, even the use of angled brackets! A quantum description is much more elegant. A perceptive reader might have noticed the similarities between \n",
    "\n",
    "$$ \\braket{E} = \\sum_{i = 0}^{N-1} X_i \\times P(i) $$\n",
    "\n",
    "And \n",
    "\n",
    "$$\n",
    "\\ket{\\psi} = \\sum_{n = 0}^{N_1} c_n \\ket{n}\n",
    "$$ \n",
    "\n",
    "We can even get $P(i) = |c_i|^2$ so perhaps we can express the expectation value in terms of the statevector and something that gives us $X$. \n",
    "\n",
    "The previous example with the $1 gain/loss coin can be repeated with a quantum mechanical treatement. Recall the operator $Z$ that gave us the win/loss for heads and tails. We would like to work out the expected earnings. We know that we can get the amount earned $X_i$\n",
    "\n",
    "$$ X_i (\\ket{i}) = Z\\ket{i}$$\n",
    "\n",
    "And we can get the probability from $\\braket{i|\\psi}$.\n",
    "\n",
    "\n",
    "This gives us the important result\n",
    "$$\n",
    "\\braket{Z} = \\braket{\\psi|Z|\\psi}\n",
    "$$\n",
    "\n",
    "We have defined the expectation value of the operator $Z$. Assuming our coin is unbiased, it has the general superposition state. We can then compute the expectation value as\n",
    "\n",
    "$$\n",
    "\\frac{1}{\\sqrt{2}} \\begin{bmatrix} 1 & 1 \\end{bmatrix} \\begin{bmatrix} 1 & 0 \\\\ 0 & -1 \\end{bmatrix} \\frac{1}{\\sqrt{2}} \\begin{bmatrix} 1 \\\\ 1 \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "\n",
    "$$\n",
    "= \\frac{1}{2}\\begin{bmatrix} 1 & 1 \\end{bmatrix} \\begin{bmatrix} 1 \\\\ -1 \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "\n",
    "$$ = \\frac{1}{2} ( 1 - 1) = 0 $$ \n",
    "\n",
    "## Chapter 4 Summary \n",
    "\n",
    "- Quantum states can be represented by column vectors \n",
    "- We can seperate out a quantum state into orthogonal components \n",
    "- The number in front of the component is the probability amplitude\n",
    "- The probability of measuring a quantum system in a given state is given by the square of the modulus of the inner product\n",
    "- The inner product of a quantum state with itself always has magnitude 1\n",
    "- Operators transform quantum states and are represented by matrices\n",
    "- The expectation value for any operator, O  is given by $\\braket{O} = \\braket{\\psi|O|\\psi}$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19.931568569324174"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np \n",
    "\n",
    "np.log2(10**6)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7d8cf412c429d163f0ec8962de5d99a5f7520d1b1380235674c38dc96da666cc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
